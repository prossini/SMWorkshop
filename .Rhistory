install.packages("yaml")
install.packages("yaml")
install.packages("yaml")
install.packages("yaml")
install.packages("yaml")
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
library(rtweet)
auth <- rtweet_app()
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
df <- search_tweets("#rstats")
boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
opts_knit$set(root.dir = "~/Documents/GitHub/Research_Methods_UoL/")
chooseCRANmirror(graphics=FALSE, ind=1)
load("~/R/tweet-collections-credentialsR.RData")
load("~/Documents/GitHub/Research_Methods_UoL/leaders_tweets.RData") # here we are loading the data you saved
load("~/Documents/GitHub/Research_Methods_UoL/COP26_tweets_16112021.RData") # here we are loading the data you saved
token <- create_token(
app = app_name, #your app name
consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
consumer_secret = app_secret)
```
rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
auth <- rtweet_app()
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
df <- search_tweets("#rstats")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
load("~/Library/Application Support/rtweet/academic_auth2.rds")
```
## Getting Started
It is good practice to call your packages in the beginning of your script by using the library command. You may also want to set your work directory and a few options, such as removing scientific notations. The code below demonstrates how you can call a package in R.
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
load("~/Library/Application Support/rtweet/academic_auth2.rds")
load("~/Library/Application Support/rtweet/academic_auth2.rds")
rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
#
auth_save(auth, "academic_auth2")
load("~/Library/Application Support/rtweet/academic_auth2.rds")
load("~/Library/Application Support/rtweet/academic_auth.rds")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
## getting tweets from one user and assigning them to an object named 'Boris'
##
boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
## getting tweets from several users and assigning them to a single object named 'leaders'
leaders <- get_timelines(c("BorisJohnson", "Keir_Starmer", "Conservatives", "UKLabour") , n=3200, retryOnRateLimit=120, resultType = "recent")
save(leaders, file = "leaders_tweets270622.RData") # to save it as an R object OR
write_as_csv(leaders, file_name = "leaders_tweets270622.csv") # to save as a CSV that can be opened in excel. This f
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
load()
save(leaders, file = "leaders_tweets270622.RData") # to save it as an R object OR
write_as_csv(leaders, file_name = "leaders_tweets270622.csv") # to save as a CSV that can be opened in excel. This function is from the package rtweet, not the same as 'write.csv' from base R.
write_as_csv(leaders, file_name = "leaders_tweets270622.csv",fileEncoding = "UTF-8") # to save as a CSV that can be opened in excel. This function is from the package rtweet, not the same as 'write.csv' from base R.
save_as_csv(leaders, file_name = "leaders_tweets270622.csv",fileEncoding = "UTF-8") # to save as a CSV that can be opened in excel. This function is from the package rtweet, not the same as 'write.csv' from base R.
load("leaders_tweets270622.RData")
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
load("leaders_tweets270622.RData")
auth_as('academic_auth')
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
load("leaders_tweets270622.RData")
auth_as('academic_auth')
colnames(leaders)
freq(leaders$screen_name) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
# options to remove scientific notations and limit digits in numeric outputs to 4
options(scipen=999, digits = 4)
# call required packages
library(rtweet)
library(tidyverse)
library(lubridate)
library(glue)
library(descr)
library(stringr)
freq(leaders$screen_name) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
freq(leaders$) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
#let's check the dates.
#First we convert the date column to a 'date' object using the function as.Date:
leaders$created_at <- as.Date(leaders$created_at)
freq(leaders$id_str) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
View(leaders)
leaders <- get_timeline(c("BorisJohnson", "Keir_Starmer", "Conservatives", "UKLabour") , n=3200, retryOnRateLimit=120, resultType = "recent")
# if we want to save this data to work on it later, just use the following command:
save(leaders, file = "leaders_tweets270622.RData") # to save it as an R object
## getting tweets from several users and assigning them to a single object named 'leaders'
leaders <- get_timeline(c("BorisJohnson", "Keir_Starmer", "Conservatives", "UKLabour") , n=3200, retryOnRateLimit=120, resultType = "recent", parse = TRUE)
head(leaders)
colnames(leaders)
head(leaders$entities)
head(leaders$metadata)
freq(leaders$id_str) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
freq(leaders$id) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
freq(leaders$source) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
freq(leaders$query) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
View(boris)
boris$entities
boris$source
View(boris[[29]][[1]])
View(boris[[7]][[1]])
install.packages("rtweet", repos = 'https://ropensci.r-universe.dev')
install.packages("rtweet", repos = 'https://ropensci.r-universe.dev')
library(rtweet)
auth_as('academic_auth2')
rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
#
auth_save(auth, "academic_auth2")
auth_as('academic_auth2')
boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
View(boris)
remove.packages("rtweet")
install.packages("rtweet")
library(rtweet)
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
library(rtweet)
rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
auth <- rtweet_app(bearer_token = "AAAAAAAAAAAAAAAAAAAAAJoCeAEAAAAANmFlceLX735jJwoT36njImGzf1M%3DGSaPe2CUAvX3Hr0nIArnkd2ZCiSIx8TiOjOBkVZe8zGup88qeh")
load("~/R/tweet-collections-credentialsR.RData")
token <- create_token(
app = app_name, #your app name
consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
consumer_secret = app_secret)
boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
boris2 <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
View(boris2)
knitr::opts_chunk$set(include = FALSE)
require("knitr")
library(rtweet)
chooseCRANmirror(graphics=FALSE, ind=1)
load("~/R/tweet-collections-credentialsR.RData")
token <- create_token(
app = app_name, #your app name
consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
consumer_secret = app_secret)
load("leaders_tweets270622.RData")
## getting tweets from several users and assigning them to a single object named 'leaders'
leaders <- get_timeline(c("BorisJohnson", "Keir_Starmer", "Conservatives", "UKLabour") , n=3200, retryOnRateLimit=120, resultType = "recent", parse = TRUE)
# if we want to save this data to work on it later, just use the following command:
save(leaders, file = "leaders_tweets270622.RData") # to save it as an R object
write_as_csv(leaders, file_name = "leaders_tweets270622.csv") # to save as a CSV that can be opened in excel. This function is from the package rtweet, not the same as 'write.csv' from base R.
colnames(leaders)
head(leaders)
freq(leaders$screen_name) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
options(scipen=999, digits = 4)
# call required packages
library(rtweet)
library(tidyverse)
library(lubridate)
library(glue)
library(descr)
library(stringr)
freq(leaders$screen_name) # unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
leaders %>% group_by(screen_name) %>%
tally()
leaders %>% group_by(screen_name) %>%
tally()
leaders %>% group_by(screen_name) %>%
count()
leaders %>%
count(screen_name)
leaders %>% group_by(screen_name) %>%
count()
leaders %>% group_by(screen_name) %>%
count()
#let's check the dates.
#First we convert the date column to a 'date' object using the function as.Date:
leaders$created_at <- as.Date(leaders$created_at)
#then, we check the earliest and latest tweet date per account:
leaders %>% group_by(screen_name) %>% summarise(min(created_at), max(created_at))
leaders_analysis <- leaders %>% filter(created_at >= '2022-01-01') #now our new data has 7040 tweets. Let's check again the dates to make sure it looks correct:
leaders_analysis %>% group_by(screen_name) %>% summarise(min(created_at), max(created_at)) # great, now all our accounts have tweets for the same period of time!
View(leaders)
leaders_analysis %>% group_by(screen_name) %>%
summarise(retweet_count)
leaders_analysis %>% group_by(screen_name) %>%
summarise(mean = retweet_count)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c(retweet_count)), ~ mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c(retweet_count)), ~ mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count')), ~ mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count')), mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count', 'like_count')), mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count', 'favorite_count')), mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count', 'favorite_count', 'reply_count')), mean)
leaders_analysis %>% group_by(screen_name) %>%
summarise_at(vars(c('retweet_count', 'favorite_count', 'reply_count')), mean, na.rm=T)
hasthag <- search_tweets(
"##sundayvibes",include_rts = FALSE, retryonratelimit = TRUE) # here we are asking the API for tweets using this hashtag, excluding RTs
View(hasthag)
usa <- stream_tweets(
lookup_coords("Liverpool"),
timeout = 60
)
View(usa)
rtweet:::citycoords
# stream tweets based in
uk <- stream_tweets(
lookup_coords("london"),
timeout = 60
)
View(uk)
# stream tweets based on location // caveat: many people don't tweet with location!
uk <- stream_tweets(
q = lookup_coords("GB"),
timeout = 60
)
# stream tweets based on location // caveat: many people don't tweet with location!
uk <- stream_tweets(
q = lookup_coords("London, GB"),
timeout = 60
)
st <- stream_tweets(q = lookup_coords("London, GB"), timeout = 30)
# stream tweets based on location // caveat: many people don't tweet with location!
st <- stream_tweets(q = "weather", timeout = 30)
View(st)
install.packages("igraph")
library(rtweet)
load("~/R/tweet-collections-credentialsR.RData")
token <- create_token(
app = app_name, #your app name
consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
consumer_secret = app_secret)
load("leaders_tweets270622.RData")
#
my <- get_friends("patyrossini")
View(my)
my_fw <- get_followers("patyrossini")
View(my_fw)
names <- lookup_users(my_fw)
names <- lookup_users(my_fw$user_id)
View(names)
# check for reciprocal links (i.e., people I follow who follow me back: )
friends <- i_fw %in% my_fw
# people I follow
i_fw <- get_friends("patyrossini")
friends <- i_fw %in% my_fw
# check for reciprocal links (i.e., people I follow who follow me back: )
friends <- my_fw %in% i_fw
knitr::purl()
knitr::purl(leedsworkshop.Rmd)
knitr::purl(input = "leedsworkshop.Rmd", output = "leedsworkshop.R",documentation = 0)
##
## library(rtweet)
##
## load("~/R/tweet-collections-credentialsR.RData")
## token <- create_token(
##   app = app_name, #your app name
##   consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
##   consumer_secret = app_secret)
##
##
## load("leaders_tweets270622.RData")
##
##
## # assign actions to an object
## x <- "something"
## # open csv files
## y <- read.csv("path.csv")
## #open RData files
## load("file.RData")
## # save as csv file
## write.csv(df, "file.csv", row.names = F)
## # save as RData file
## save(df, file = "df.RData")
## # options to remove scientific notations and limit digits in numeric outputs to 4
## options(scipen=999, digits = 4)
## # call required packages
## library(rtweet)
## library(tidyverse)
## library(lubridate)
## library(glue)
## library(descr)
## library(stringr)
##
##
## ## paste use your credentials here.
##
## ## Create a token
## token <- create_token(
##   app = 'app_name', #your app name
##   consumer_key = "consumerKey", #consumer key for your app, replace the text between quotes with your app's key
##   consumer_secret = 'consumerSecret') #consumer secret for your app, replace the text between quotes with your app's secret
##
##
## ## getting tweets from one user and assigning them to an object named 'Boris'
## ##
## boris <- get_timeline("BorisJohnson", n=3200, retryOnRateLimit=120, resultType = "recent")
##
##
## ## getting tweets from several users and assigning them to a single object named 'leaders'
## leaders <- get_timeline(c("BorisJohnson", "Keir_Starmer", "Conservatives", "UKLabour") , n=3200, retryOnRateLimit=120, resultType = "recent", parse = TRUE)
##
## # if we want to save this data to work on it later, just use the following command:
## save(leaders, file = "leaders_tweets270622.RData") # to save it as an R object
## write_as_csv(leaders, file_name = "leaders_tweets270622.csv") # to save as a CSV that can be opened in excel. This function is from the package rtweet, not the same as 'write.csv' from base R.
## colnames(leaders)
## head(leaders)
##
## freq(leaders$screen_name) # freq is a function of the package descr. Unsurprisingly, we have about 3200 for all accounts, as this is the maximum we can retrieve using the free API
##
## # we can use dplyr to do the same:
##
## leaders %>% group_by(screen_name) %>%
##   count()
##
##
## #let's check the dates.
## #First we convert the date column to a 'date' object using the function as.Date:
## leaders$created_at <- as.Date(leaders$created_at)
##
## #then, we check the earliest and latest tweet date per account:
## leaders %>% group_by(screen_name) %>% summarise(min(created_at), max(created_at))
##
## # from this we notice that tweets by Boris Johnson go way back to July, 2019, but all others were some time in 2020.
## # To make our dataset comparable, let's limit the analysis to tweets posted in 2022, filtering by date.
## # I will assign the filtered dataset to a new object just in case we want to return to the full set some other time.
##
## leaders_analysis <- leaders %>% filter(created_at >= '2022-01-01') #now our new data has 7040 tweets. Let's check again the dates to make sure it looks correct:
## leaders_analysis %>% group_by(screen_name) %>% summarise(min(created_at), max(created_at)) # great, now all our accounts have tweets for the same period of time!
##
##
##
## leaders_analysis %>% group_by(screen_name) %>%
##   summarise_at(vars(c('retweet_count', 'favorite_count', 'reply_count')), mean, na.rm=T)
## hasthag <- search_tweets(
##   "##sundayvibes",include_rts = FALSE, retryonratelimit = TRUE) # here we are asking the API for tweets using this hashtag, excluding RTs
##
## # search terms using search operators (AND, OR)
##
## rt <- search_tweets(q = "rstats AND python")
##
##
## # people I follow
## i_fw <- get_friends("patyrossini")
## # people following me
## my_fw <- get_followers("patyrossini")
##
##
## # stream tweets based on search (can use advance operator)
## st <- stream_tweets(q = "weather", timeout = 30)
##
## # stream random sample
## sr <- stream_tweets(q = "", timeout = 30)
##
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(include = TRUE)
library(rtweet)
load("~/R/tweet-collections-credentialsR.RData")
token <- create_token(
app = app_name, #your app name
consumer_key = app_key, #consumer key for your app, replace the text between quotes with your app's key
consumer_secret = app_secret)
load("leaders_tweets270622.RData")
install.packages("descr")
install.packages("asdfaga")
